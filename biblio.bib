@article{suksamosorn_post-processing_2021,
  title        = {Post-Processing of {NWP} Forecasts Using Kalman Filtering With Operational Constraints for Day-Ahead Solar Power Forecasting in Thailand},
  volume       = {9},
  issn         = {2169-3536},
  url          = {https://ieeexplore.ieee.org/document/9494359/},
  doi          = {10.1109/ACCESS.2021.3099481},
  abstract     = {Solar power forecasting with a day-ahead horizon has played an important role in the operational planning of generating units in power system operations. We aim to develop a solar power forecasting model suitable for a tropical climate, using Thailand as a model, and hence present a linear recursive regression model as a post-processing step for reducing the errors obtained from the Weather Research and Forecasting ({WRF}) model. This model consists of submodels, each of which predicts the solar irradiance of a particular time of the day. By using a stepwise regression method, we found that {WRF} forecasts of irradiance, temperature, relative humidity, and the solar zenith angle were selected as highly relevant inputs of the model. The regression model coefﬁcients are updated according to a Kalman ﬁltering ({KF}) scheme so that the model can ﬂexibly adapt to ﬂuctuations in the solar irradiance. We then modify the {KF} update formula to accommodate the limitation in measurement availability at the time of executing the forecasts. The proposed {KF} formula can be generalized to ﬁnd the optimal prediction given that the available measurements are mapped by an afﬁne transformation. The obtained results using actual data from a solar rooftop system located in the central region of Thailand showed that the normalized rootmean-square error ({NRMSE}) of solar power prediction was about 12-13\%, which was decreased from the {NRMSE} of the {WRF} model by 7-12\% on average. This improvement was the best out of similar post-processing methods based on the model output statistics framework.},
  pages        = {105409--105423},
  journaltitle = {{IEEE} Access},
  shortjournal = {{IEEE} Access},
  author       = {Suksamosorn, Supachai and Hoonchareon, Naebboon and Songsiri, Jitkomut},
  urldate      = {2023-04-13},
  date         = {2021},
  langid       = {english},
  file         = {Suksamosorn et al. - 2021 - Post-Processing of NWP Forecasts Using Kalman Filt.pdf:C\:\\Users\\maccou\\Zotero\\storage\\T9EY8336\\Suksamosorn et al. - 2021 - Post-Processing of NWP Forecasts Using Kalman Filt.pdf:application/pdf}
}

@misc{yu_hyper-parameter_2020,
  title      = {Hyper-Parameter Optimization: A Review of Algorithms and Applications},
  url        = {http://arxiv.org/abs/2003.05689},
  shorttitle = {Hyper-Parameter Optimization},
  abstract   = {Since deep neural networks were developed, they have made huge contributions to peoples everyday lives. Machine learning provides more rational advice than humans are capable of in almost every aspect of daily life. However, despite this achievement, the design and training of neural networks are still challenging and unpredictable procedures that have been alleged to be alchemy. To lower the technical thresholds for common users, automated hyper-parameter optimization ({HPO}) has become a popular topic in both academic and industrial areas. This paper provides a review of the most essential topics on {HPO}. The ﬁrst section introduces the key hyper-parameters related to model training and structure, and discusses their importance and methods to deﬁne the value range. Then, the research focuses on major optimization algorithms and their applicability, covering their eﬃciency and accuracy especially for deep learning networks. This study next reviews major services and tool-kits for {HPO}, comparing their support for state-of-the-art searching algorithms, feasibility with major deep-learning frameworks, and extensibility for new modules designed by users. The paper concludes with problems that exist when {HPO} is applied to deep learning, a comparison between optimization algorithms, and prominent approaches for model evaluation with limited computational resources.},
  number     = {{arXiv}:2003.05689},
  publisher  = {{arXiv}},
  author     = {Yu, Tong and Zhu, Hong},
  urldate    = {2023-04-13},
  date       = {2020-03-12},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2003.05689 [cs, stat]},
  keywords   = {Statistics - Machine Learning, Computer Science - Machine Learning},
  file       = {Yu et Zhu - 2020 - Hyper-Parameter Optimization A Review of Algorith.pdf:C\:\\Users\\maccou\\Zotero\\storage\\X6TD5GJ5\\Yu et Zhu - 2020 - Hyper-Parameter Optimization A Review of Algorith.pdf:application/pdf}
}

@article{mayer_calibration_2023,
  title        = {Calibration of deterministic {NWP} forecasts and its impact on verification},
  volume       = {39},
  issn         = {01692070},
  url          = {https://linkinghub.elsevier.com/retrieve/pii/S0169207022000486},
  doi          = {10.1016/j.ijforecast.2022.03.008},
  abstract     = {Deterministic forecasts (as opposed to ensemble or probabilistic forecasts) issued by numerical weather prediction ({NWP}) models require post-processing. Such corrective procedure can be viewed as a form of calibration. It is well known that, based on different objective functions, e.g., minimizing the mean square error or the mean absolute error, the calibrated forecasts have different impacts on verification. In this regard, this paper investigates how a calibration directive can affect various aspects of forecast quality outlined in the Murphy–Winkler distribution-oriented verification framework. It is argued that the correlation coefficient is the best measure for the potential performance of {NWP} forecast verification when linear calibration is involved, because (1) it is not affected by the directive of linear calibration, (2) it can be used to compute the skill score of the linearly calibrated forecasts, and (3) it can avoid the potential deficiency of using squared error to rank forecasts. Since no single error metric can fully represent all aspects of forecast quality, forecasters need to understand the trade-offs between different calibration strategies. To echo the increasing need to bridge atmospheric sciences, renewable energy engineering, and power system engineering, as to move toward the grand goal of carbon neutrality, this paper first provides a brief introduction to solar forecasting, and then revolves its discussion around a solar forecasting case study, such that the readers of this journal can gain further understanding on the subject and thus potentially contribute to it.},
  pages        = {981--991},
  number       = {2},
  journaltitle = {International Journal of Forecasting},
  shortjournal = {International Journal of Forecasting},
  author       = {Mayer, Martin János and Yang, Dazhi},
  urldate      = {2023-04-13},
  date         = {2023-04},
  langid       = {english},
  file         = {Mayer et Yang - 2023 - Calibration of deterministic NWP forecasts and its.pdf:C\:\\Users\\maccou\\Zotero\\storage\\Q3ZXS8W8\\Mayer et Yang - 2023 - Calibration of deterministic NWP forecasts and its.pdf:application/pdf}
}

@article{verbois_statistical_2022,
  title        = {Statistical learning for {NWP} post-processing: A benchmark for solar irradiance forecasting},
  volume       = {238},
  issn         = {0038092X},
  url          = {https://linkinghub.elsevier.com/retrieve/pii/S0038092X22001839},
  doi          = {10.1016/j.solener.2022.03.017},
  shorttitle   = {Statistical learning for {NWP} post-processing},
  abstract     = {The share of solar power in the global and local energy mixes has increased dramatically in the past decade. Consequently, there has been a significant rise in the interest for solar power forecasting, for different time horizons, ranging from few minutes to seasons. For day-ahead forecasts, combination of Numerical Weather Prediction ({NWP}) models and post-processing algorithms is the most popular approach. Many recent publications have proposed innovative {NWP} post-processing methods. However, because different works use different datasets, metrics, and even cross-validation methods, it is rarely possible to fairly compare results across several papers.},
  pages        = {132--149},
  journaltitle = {Solar Energy},
  shortjournal = {Solar Energy},
  author       = {Verbois, Hadrien and Saint-Drenan, Yves-Marie and Thiery, Alexandre and Blanc, Philippe},
  urldate      = {2023-04-13},
  date         = {2022-05},
  langid       = {english},
  file         = {Verbois et al. - 2022 - Statistical learning for NWP post-processing A be.pdf:C\:\\Users\\maccou\\Zotero\\storage\\F2X6DWJH\\Verbois et al. - 2022 - Statistical learning for NWP post-processing A be.pdf:application/pdf}
}

@article{lorenz_benchmarking_nodate,
  title    = {{Benchmarking} {of} {different} {approaches} {to} {forecast} {solar} {irradiance}},
  abstract = {Power generation from photovoltaic systems is highly variable due to its dependence on meteorological conditions. An efficient use of this fluctuating energy source requires reliable forecast information for management and operation strategies. Due to the strong increase of solar power generation the prediction of solar yields becomes more and more important. As a consequence, in the last years various research organisations and companies have developed different methods to forecast irradiance as a basis for respective power forecasts. For the end-users of these forecasts it is important that standardized methodology is used when presenting results on the accuracy of a prediction model in order to get a clear idea on the advantages of a specific approach.},
  author   = {Lorenz, Elke and Remund, Jan and Müller, Stefan C and Traunmüller, Wolfgang and Steinmaurer, Gerald and Pozo, David and Lara, Vicente and Ramirez, Lourdes and Romeo, Martin Gaston and Kurz, Christian and Pomares, Luis Martin and Guerrero, Carlos Geijo},
  langid   = {english}
}

@misc{kfbasis,
  author = {Alex Becker},
  title  = {KalmanFilter.NET},
  url    = {https://www.kalmanfilter.net/default.aspx}
}

@misc{kfpractise,
  author = {Roger R. Labbe},
  title  = {Kalman and bayesian filters in Python},
  url    = {https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python}
}

@misc{GBMbasis,
  author = {Ajitesh Kumar},
  title  = {Gradient Boosting algorithm: Concepts, example},
  url    = {https://vitalflux.com/gradient-boosting-algorithm-concepts-example/?utm_content=cmp-true}
}

@misc{GBMpractise,
  author = {Carolina Bento},
  title  = {Gradient Boosted Decision Trees Explained with a Real-Life Example and Some Python Code},
  url    = {https://towardsdatascience.com/gradient-boosted-decision-trees-explained-with-a-real-life-example-and-some-python-code-77cee4ccf5e}
}

@misc{SVR,
  author = {Tom Sharp},
  title  = {An introduction to SVR},
  url    = {https://towardsdatascience.com/an-introduction-to-support-vector-regression-svr-a3ebc1672c2}
}

@misc{RF,
  author = {Carolina Bento},
  title  = {Random Forests Algorithm explained with a real-life example and some Python code},
  url    = {https://towardsdatascience.com/random-forests-algorithm-explained-with-a-real-life-example-and-some-python-code-affbfa5a942c}
}

@misc{myrepo,
  author = {Martin ACCOU},
  title  = {My intership GitLab repo},
  url    = {https://gitlab.soleka.org/maccou/maccou}
}

@misc{sklearnlinear,
  author = {scikit-learn},
  title  = {Scikit-learn regression models},
  url    = {https://scikit-learn.org/stable/modules/linear_model.html}
}